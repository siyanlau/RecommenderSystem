{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XlRrfeMuD-R5",
    "outputId": "121a32c7-2e20-4f1a-a9e7-6b16955db7c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyspark in /ext3/pyspark/lib/python3.8/site-packages (3.1.2)\n",
      "Requirement already satisfied: py4j==0.10.9 in /ext3/pyspark/lib/python3.8/site-packages (from pyspark) (0.10.9)\n"
     ]
    }
   ],
   "source": [
    "! pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Jef3yOo0D1bz"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import collect_set, collect_list\n",
    "from pyspark.sql import functions\n",
    "from pyspark.sql.functions import col, lit, when, expr, desc, size\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-dTLzTi9EDx7"
   },
   "outputs": [],
   "source": [
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MovieTwin\") \\\n",
    "    .master(\"spark://cs103:58270\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# spark = SparkSession.builder.appName(\"MovieTwin\").config(\"spark.executor.instances\", \"10\").config(\"spark.executor.memory\", \"4g\").config(\"spark.executor.cores\", \"2\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://cs103.hpc.nyu.edu:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://cs103:58270</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>MovieTwin</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=spark://cs103:58270 appName=MovieTwin>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = spark.sparkContext\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5PbNiTg19_2"
   },
   "source": [
    "## Data Loading and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DNIv5f5BqHgh",
    "outputId": "52c0a8b0-a25f-47bd-dfea-742d46fa0e1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 976 µs, sys: 1.53 ms, total: 2.5 ms\n",
      "Wall time: 1.41 s\n",
      "CPU times: user 499 µs, sys: 553 µs, total: 1.05 ms\n",
      "Wall time: 36.5 ms\n"
     ]
    }
   ],
   "source": [
    "# Load only the movieId\n",
    "%time movies = spark.read.csv(\"ml-latest/movies-large.csv\", header=True, inferSchema=True, schema=\"movieId INT\")\n",
    "\n",
    "# Load only the userId and movieId columns\n",
    "# By loading in only the relevant data, we reduce loading time to 1/20!\n",
    "%time ratings = spark.read.csv(\"ml-latest/ratings-large.csv\", header=True, inferSchema=True, schema=\"userId INT, movieId INT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5ryIqVJhZ6F0"
   },
   "outputs": [],
   "source": [
    "# set variables from documentation - avoid some unnecessary data loading\n",
    "# the number have been verified by loading the actual datasets\n",
    "\n",
    "# num_movies = 9742\n",
    "# num_users = 610\n",
    "\n",
    "num_movies = 86537\n",
    "num_users = 330975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5zooY3JWcy0X"
   },
   "outputs": [],
   "source": [
    "distinct_movie_ids = sorted(set(row.movieId for row in movies.collect()))\n",
    "movie_id_index_map = {movie_id: index for index, movie_id in enumerate(distinct_movie_ids)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_81rB89jj45"
   },
   "source": [
    "**Consideration**: User IDs are not consecutive, neither are movie IDs. For our purposes, we do not care about actual movie IDs, as long as they are aligned so we can compute user similarity. However, we do care about actual user IDs in the final step. For now, we can pretend the user are indexed by consecutive integers, and later (when we get the top 100 pairs) convert those numerals back to actual user IDs using a dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTKmCQoYzgEz"
   },
   "source": [
    "**Loading Optimization**: Using the pivot_table function takes forever, likely due to the varying length of the list of movies. Anticipating a much larger dataset, I wrote a custom function to minimize loading time. It first creates an empty table of size num_users x num_movies, then compute the list of movies watched by each user, and map each movieId to a movieIndex, and finally filling the cell `[userIndex, movieIndex]`with 1.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NAuu84UNmY1u"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "def load_data(ratings, movies):\n",
    "    # create a movieId to movieIndex (0-indexed) mapping\n",
    "    distinct_movie_ids = sorted(set(row.movieId for row in movies.collect()))\n",
    "    movie_id_index_map = {movie_id: index for index, movie_id in enumerate(distinct_movie_ids)}\n",
    "\n",
    "    # create a dataframe representing the list of movies watched by each user\n",
    "    user_movies = group_ratings_by_user(ratings)\n",
    "    user_movies_df = spark.createDataFrame([(user_id, movies) for user_id, movies in user_movies.items()], ['userId', 'movies'])\n",
    "    user_movies_df.show(5)\n",
    "\n",
    "    # Convert user-movie mapping to sparse vectors\n",
    "    user_movie_sparse_vectors = user_movies_df.rdd.map(lambda row: (row.userId, sparse_vector_from_movies(row.movies, movie_id_index_map)))\n",
    "\n",
    "    # Convert RDD to DataFrame\n",
    "    user_movie_sparse_vectors = user_movie_sparse_vectors.toDF(['userId', 'movieVector'])\n",
    "\n",
    "    return user_movie_sparse_vectors\n",
    "\n",
    "def sparse_vector_from_movies(movies, movie_id_index_map):\n",
    "    indices = sorted(movie_id_index_map[movieId] for movieId in movies)\n",
    "    values = [1] * len(indices)  # Assuming all entries are 1\n",
    "    return Vectors.sparse(num_movies, indices, values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "BjW1ldHr9qF6"
   },
   "outputs": [],
   "source": [
    "def group_ratings_by_user(ratings):\n",
    "    user_movies_df = ratings.groupBy('userId').agg(collect_list('movieId').alias('movies')).filter(size('movies') >= 20)\n",
    "    user_movies = {row.userId: row.movies for row in user_movies_df.collect()}\n",
    "    return user_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:========================================================>(79 + 1) / 80]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|              movies|\n",
      "+------+--------------------+\n",
      "|     1|[1, 110, 158, 260...|\n",
      "|     2|[1, 2, 6, 10, 11,...|\n",
      "|     3|[296, 318, 858, 2...|\n",
      "|     4|[260, 318, 356, 5...|\n",
      "|     5|[47, 175, 257, 31...|\n",
      "|     6|[24, 47, 60, 110,...|\n",
      "|     7|[1, 3, 11, 21, 25...|\n",
      "|     9|[2, 3, 5, 6, 10, ...|\n",
      "|    10|[1, 32, 47, 260, ...|\n",
      "|    11|[260, 318, 356, 5...|\n",
      "|    12|[1, 6, 9, 12, 25,...|\n",
      "|    13|[838, 858, 1025, ...|\n",
      "|    14|[1, 2, 10, 17, 19...|\n",
      "|    15|[16, 50, 223, 260...|\n",
      "|    17|[104, 527, 1101, ...|\n",
      "|    21|[1, 2, 10, 32, 39...|\n",
      "|    22|[16, 18, 32, 47, ...|\n",
      "|    24|[1, 9, 11, 14, 15...|\n",
      "|    26|[50, 111, 296, 31...|\n",
      "|    27|[111, 318, 356, 9...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "user_movies = ratings.repartitionByRange(col(\"userId\")).groupBy('userId').agg(collect_list('movieId').alias('movies')).filter(size('movies') >= 20)\n",
    "user_movies.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XptKIYsM1inj",
    "outputId": "078bebfd-0f6d-4be0-b69e-5f5da8b1b760"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/15 16:48:09 WARN TaskSetManager: Stage 7 contains a task of very large size (1107 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/05/15 16:48:11 WARN TaskSetManager: Stage 8 contains a task of very large size (1107 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|              movies|\n",
      "+------+--------------------+\n",
      "|   148|[1, 2, 6, 7, 10, ...|\n",
      "|   463|[1, 111, 223, 260...|\n",
      "|   496|[6, 10, 17, 21, 2...|\n",
      "|   833|[47, 110, 260, 26...|\n",
      "|  1088|[1, 2, 6, 10, 21,...|\n",
      "+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.61 s, sys: 790 ms, total: 8.4 s\n",
      "Wall time: 21 s\n"
     ]
    }
   ],
   "source": [
    "%time loaded_data = load_data(ratings, movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5-cbx674FpzP",
    "outputId": "cb82a4f9-c16d-448b-90e2-7a5351b470f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions: 80\n"
     ]
    }
   ],
   "source": [
    "num_partitions = loaded_data.rdd.getNumPartitions()\n",
    "print(\"Number of partitions:\", num_partitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k6mQtq7x2FBm"
   },
   "source": [
    "## MinHash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "xlRWqXi86VHR"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import MinHashLSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_repartitioned = loaded_data.repartitionByRange(10, \"userId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/15 16:48:12 WARN TaskSetManager: Stage 9 contains a task of very large size (1107 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|         movieVector|\n",
      "+------+--------------------+\n",
      "|   148|(86537,[0,1,5,6,9...|\n",
      "|   463|(86537,[0,109,220...|\n",
      "|   496|(86537,[5,9,16,20...|\n",
      "|   833|(86537,[46,108,25...|\n",
      "|  1088|(86537,[0,1,5,9,2...|\n",
      "|  1238|(86537,[5,9,15,16...|\n",
      "|  1342|(86537,[31,46,228...|\n",
      "|  1645|(86537,[0,16,27,4...|\n",
      "|  1829|(86537,[4,30,33,4...|\n",
      "|  1959|(86537,[0,1,10,47...|\n",
      "+------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "loaded_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/15 16:48:17 WARN TaskSetManager: Stage 10 contains a task of very large size (1107 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(movieVector=SparseVector(86537, {0: 1.0, 1: 1.0, 5: 1.0, 6: 1.0, 9: 1.0, 20: 1.0, 24: 1.0, 31: 1.0, 33: 1.0, 46: 1.0, 49: 1.0, 69: 1.0, 93: 1.0, 108: 1.0, 124: 1.0, 148: 1.0, 149: 1.0, 158: 1.0, 159: 1.0, 162: 1.0, 170: 1.0, 188: 1.0, 196: 1.0, 243: 1.0, 257: 1.0, 289: 1.0, 292: 1.0, 313: 1.0, 314: 1.0, 324: 1.0, 343: 1.0, 344: 1.0, 345: 1.0, 348: 1.0, 351: 1.0, 352: 1.0, 356: 1.0, 359: 1.0, 362: 1.0, 368: 1.0, 372: 1.0, 374: 1.0, 377: 1.0, 378: 1.0, 421: 1.0, 429: 1.0, 435: 1.0, 437: 1.0, 449: 1.0, 452: 1.0, 459: 1.0, 469: 1.0, 470: 1.0, 475: 1.0, 486: 1.0, 504: 1.0, 506: 1.0, 512: 1.0, 522: 1.0, 528: 1.0, 534: 1.0, 536: 1.0, 579: 1.0, 580: 1.0, 581: 1.0, 582: 1.0, 584: 1.0, 585: 1.0, 586: 1.0, 588: 1.0, 589: 1.0, 600: 1.0, 637: 1.0, 642: 1.0, 662: 1.0, 705: 1.0, 718: 1.0, 721: 1.0, 722: 1.0, 734: 1.0, 764: 1.0, 784: 1.0, 789: 1.0, 814: 1.0, 840: 1.0, 876: 1.0, 878: 1.0, 879: 1.0, 881: 1.0, 883: 1.0, 884: 1.0, 887: 1.0, 890: 1.0, 891: 1.0, 892: 1.0, 893: 1.0, 895: 1.0, 898: 1.0, 899: 1.0, 900: 1.0, 902: 1.0, 903: 1.0, 909: 1.0, 912: 1.0, 915: 1.0, 919: 1.0, 920: 1.0, 927: 1.0, 930: 1.0, 931: 1.0, 932: 1.0, 933: 1.0, 935: 1.0, 947: 1.0, 948: 1.0, 972: 1.0, 996: 1.0, 1005: 1.0, 1013: 1.0, 1024: 1.0, 1047: 1.0, 1050: 1.0, 1051: 1.0, 1052: 1.0, 1053: 1.0, 1054: 1.0, 1057: 1.0, 1058: 1.0, 1059: 1.0, 1062: 1.0, 1063: 1.0, 1065: 1.0, 1067: 1.0, 1068: 1.0, 1070: 1.0, 1074: 1.0, 1097: 1.0, 1099: 1.0, 1101: 1.0, 1108: 1.0, 1151: 1.0, 1154: 1.0, 1156: 1.0, 1157: 1.0, 1164: 1.0, 1166: 1.0, 1167: 1.0, 1168: 1.0, 1169: 1.0, 1170: 1.0, 1171: 1.0, 1174: 1.0, 1176: 1.0, 1177: 1.0, 1179: 1.0, 1180: 1.0, 1182: 1.0, 1183: 1.0, 1184: 1.0, 1186: 1.0, 1188: 1.0, 1189: 1.0, 1190: 1.0, 1191: 1.0, 1193: 1.0, 1194: 1.0, 1199: 1.0, 1201: 1.0, 1202: 1.0, 1203: 1.0, 1206: 1.0, 1207: 1.0, 1209: 1.0, 1212: 1.0, 1214: 1.0, 1217: 1.0, 1220: 1.0, 1223: 1.0, 1224: 1.0, 1226: 1.0, 1227: 1.0, 1229: 1.0, 1230: 1.0, 1231: 1.0, 1232: 1.0, 1233: 1.0, 1234: 1.0, 1237: 1.0, 1239: 1.0, 1241: 1.0, 1242: 1.0, 1243: 1.0, 1245: 1.0, 1249: 1.0, 1250: 1.0, 1251: 1.0, 1252: 1.0, 1254: 1.0, 1255: 1.0, 1258: 1.0, 1260: 1.0, 1264: 1.0, 1265: 1.0, 1267: 1.0, 1268: 1.0, 1269: 1.0, 1270: 1.0, 1273: 1.0, 1287: 1.0, 1299: 1.0, 1310: 1.0, 1315: 1.0, 1321: 1.0, 1334: 1.0, 1335: 1.0, 1336: 1.0, 1337: 1.0, 1338: 1.0, 1339: 1.0, 1340: 1.0, 1341: 1.0, 1342: 1.0, 1351: 1.0, 1355: 1.0, 1357: 1.0, 1359: 1.0, 1360: 1.0, 1370: 1.0, 1435: 1.0, 1452: 1.0, 1460: 1.0, 1475: 1.0, 1489: 1.0, 1497: 1.0, 1517: 1.0, 1523: 1.0, 1527: 1.0, 1529: 1.0, 1550: 1.0, 1552: 1.0, 1559: 1.0, 1566: 1.0, 1579: 1.0, 1601: 1.0, 1610: 1.0, 1612: 1.0, 1614: 1.0, 1618: 1.0, 1620: 1.0, 1625: 1.0, 1631: 1.0, 1637: 1.0, 1640: 1.0, 1655: 1.0, 1656: 1.0, 1663: 1.0, 1677: 1.0, 1689: 1.0, 1707: 1.0, 1722: 1.0, 1727: 1.0, 1744: 1.0, 1757: 1.0, 1760: 1.0, 1787: 1.0, 1793: 1.0, 1818: 1.0, 1820: 1.0, 1828: 1.0, 1829: 1.0, 1838: 1.0, 1856: 1.0, 1865: 1.0, 1868: 1.0, 1870: 1.0, 1871: 1.0, 1872: 1.0, 1873: 1.0, 1876: 1.0, 1879: 1.0, 1893: 1.0, 1905: 1.0, 1908: 1.0, 1911: 1.0, 1912: 1.0, 1916: 1.0, 1917: 1.0, 1920: 1.0, 1922: 1.0, 1924: 1.0, 1930: 1.0, 1932: 1.0, 1939: 1.0, 1957: 1.0, 1965: 1.0, 1978: 1.0, 1986: 1.0, 1987: 1.0, 1989: 1.0, 1992: 1.0, 2004: 1.0, 2010: 1.0, 2015: 1.0, 2019: 1.0, 2025: 1.0, 2027: 1.0, 2028: 1.0, 2040: 1.0, 2050: 1.0, 2058: 1.0, 2070: 1.0, 2071: 1.0, 2084: 1.0, 2103: 1.0, 2104: 1.0, 2118: 1.0, 2140: 1.0, 2145: 1.0, 2152: 1.0, 2154: 1.0, 2157: 1.0, 2162: 1.0, 2177: 1.0, 2196: 1.0, 2197: 1.0, 2198: 1.0, 2200: 1.0, 2203: 1.0, 2211: 1.0, 2220: 1.0, 2222: 1.0, 2230: 1.0, 2253: 1.0, 2255: 1.0, 2258: 1.0, 2261: 1.0, 2262: 1.0, 2268: 1.0, 2272: 1.0, 2275: 1.0, 2278: 1.0, 2280: 1.0, 2283: 1.0, 2285: 1.0, 2300: 1.0, 2302: 1.0, 2305: 1.0, 2311: 1.0, 2314: 1.0, 2315: 1.0, 2316: 1.0, 2318: 1.0, 2319: 1.0, 2320: 1.0, 2321: 1.0, 2329: 1.0, 2340: 1.0, 2362: 1.0, 2363: 1.0, 2364: 1.0, 2385: 1.0, 2430: 1.0, 2433: 1.0, 2436: 1.0, 2437: 1.0, 2438: 1.0, 2439: 1.0, 2440: 1.0, 2441: 1.0, 2442: 1.0, 2462: 1.0, 2480: 1.0, 2522: 1.0, 2525: 1.0, 2526: 1.0, 2537: 1.0, 2542: 1.0, 2549: 1.0, 2550: 1.0, 2551: 1.0, 2556: 1.0, 2565: 1.0, 2570: 1.0, 2572: 1.0, 2576: 1.0, 2578: 1.0, 2591: 1.0, 2608: 1.0, 2624: 1.0, 2631: 1.0, 2636: 1.0, 2643: 1.0, 2669: 1.0, 2670: 1.0, 2671: 1.0, 2672: 1.0, 2696: 1.0, 2699: 1.0, 2703: 1.0, 2705: 1.0, 2712: 1.0, 2716: 1.0, 2727: 1.0, 2760: 1.0, 2765: 1.0, 2766: 1.0, 2771: 1.0, 2798: 1.0, 2823: 1.0, 2824: 1.0, 2825: 1.0, 2826: 1.0, 2834: 1.0, 2837: 1.0, 2852: 1.0, 2854: 1.0, 2855: 1.0, 2856: 1.0, 2857: 1.0, 2859: 1.0, 2876: 1.0, 2893: 1.0, 2894: 1.0, 2895: 1.0, 2897: 1.0, 2898: 1.0, 2899: 1.0, 2901: 1.0, 2926: 1.0, 2936: 1.0, 2939: 1.0, 2940: 1.0, 2941: 1.0, 2942: 1.0, 2944: 1.0, 2946: 1.0, 2968: 1.0, 2969: 1.0, 2973: 1.0, 2977: 1.0, 2978: 1.0, 2981: 1.0, 2995: 1.0, 3002: 1.0, 3005: 1.0, 3007: 1.0, 3009: 1.0, 3011: 1.0, 3014: 1.0, 3029: 1.0, 3060: 1.0, 3063: 1.0, 3076: 1.0, 3107: 1.0, 3111: 1.0, 4955: 1.0}))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_row = loaded_data.select('movieVector').head(1)\n",
    "first_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uWGDC5SIYckZ",
    "outputId": "6a773445-9480-4ce7-9e08-1cbaa5797951"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/15 16:48:21 WARN TaskSetManager: Stage 11 contains a task of very large size (1107 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "minhash_lsh = MinHashLSH(inputCol=\"movieVector\", outputCol=\"hashes\", numHashTables=5)\n",
    "\n",
    "# Fit the model to the data\n",
    "model = minhash_lsh.fit(loaded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary:\n",
      "MinHashLSHModel: uid=MinHashLSH_15c21929d621, numHashTables=5\n"
     ]
    }
   ],
   "source": [
    "print(\"Model summary:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "replica = loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.3\n",
    "\n",
    "# Perform the approximate similarity join\n",
    "similar_pairs = model.approxSimilarityJoin(loaded_data, replica, threshold, distCol=\"JaccardDistance\")\\\n",
    "                    .filter(col(\"datasetA.userId\") < col(\"datasetB.userId\"))\\\n",
    "                    .select(\n",
    "                        col(\"datasetA.userId\").alias(\"idA\"),\n",
    "                        col(\"datasetB.userId\").alias(\"idB\"),\n",
    "                        col(\"JaccardDistance\")\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[idA: bigint, idB: bigint, JaccardDistance: double]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/15 13:54:11 WARN TaskSetManager: Stage 23 contains a task of very large size (1107 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/05/15 13:54:14 WARN TaskSetManager: Stage 24 contains a task of very large size (1107 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 26:==============================================>       (172 + 8) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---------------+\n",
      "|   idA|   idB|JaccardDistance|\n",
      "+------+------+---------------+\n",
      "| 85653| 95175|            0.0|\n",
      "|305904|314085|            0.0|\n",
      "| 51160| 62784|            0.0|\n",
      "| 57540|282312|            0.0|\n",
      "| 77600|132822|            0.0|\n",
      "| 64872|293880|            0.0|\n",
      "| 82321|236540|            0.0|\n",
      "|158283|329248|            0.0|\n",
      "| 82321|277862|            0.0|\n",
      "| 19061|241234|            0.0|\n",
      "| 97685|134981|            0.0|\n",
      "| 22437| 23527|            0.0|\n",
      "|234310|325068|            0.0|\n",
      "|  3799| 97685|            0.0|\n",
      "| 12125| 47942|            0.0|\n",
      "| 50132| 87155|            0.0|\n",
      "|183207|222150|            0.0|\n",
      "|122621|235844|            0.0|\n",
      "| 77318|227884|            0.0|\n",
      "| 83065|183123|            0.0|\n",
      "| 93572|177183|            0.0|\n",
      "|  3799|162798|            0.0|\n",
      "| 14186|253377|            0.0|\n",
      "| 51160|313610|            0.0|\n",
      "| 93572|119474|            0.0|\n",
      "| 22437|313463|            0.0|\n",
      "|  3799|227884|            0.0|\n",
      "|238288|265718|            0.0|\n",
      "| 59869| 63309|            0.0|\n",
      "|147789|279965|            0.0|\n",
      "| 77600|163485|            0.0|\n",
      "|123530|161017|            0.0|\n",
      "| 14186|249611|            0.0|\n",
      "|156709|235844|            0.0|\n",
      "|263035|304933|            0.0|\n",
      "| 47942|134981|            0.0|\n",
      "| 14186| 87155|            0.0|\n",
      "|120522|309198|            0.0|\n",
      "|248461|266708|            0.0|\n",
      "| 18356|265259|            0.0|\n",
      "| 77318|170112|            0.0|\n",
      "| 49647|168141|            0.0|\n",
      "| 14186| 22437|            0.0|\n",
      "|183123|249077|            0.0|\n",
      "| 87155| 93572|            0.0|\n",
      "| 71302|279965|            0.0|\n",
      "|169845|277862|            0.0|\n",
      "| 88603|283959|            0.0|\n",
      "| 85653|291625|            0.0|\n",
      "| 14186| 50132|            0.0|\n",
      "| 12125| 88344|            0.0|\n",
      "|264494|266605|            0.0|\n",
      "|175379|248242|            0.0|\n",
      "|163485|243711|            0.0|\n",
      "| 92534|313668|            0.0|\n",
      "| 74957| 91881|            0.0|\n",
      "| 12125| 77318|            0.0|\n",
      "|230806|277862|            0.0|\n",
      "|169860|277862|            0.0|\n",
      "|134981|248242|            0.0|\n",
      "| 77318| 88344|            0.0|\n",
      "| 47942| 65538|            0.0|\n",
      "| 12125|170112|            0.0|\n",
      "| 56180|264494|            0.0|\n",
      "| 82321|141201|            0.0|\n",
      "|119474|253377|            0.0|\n",
      "|313668|325068|            0.0|\n",
      "| 82915| 99030|            0.0|\n",
      "| 87155|253377|            0.0|\n",
      "| 47942| 97685|            0.0|\n",
      "| 33604|234131|            0.0|\n",
      "|  7038|169493|            0.0|\n",
      "|107031|198462|            0.0|\n",
      "| 38643|172316|            0.0|\n",
      "| 23527|313463|            0.0|\n",
      "| 65538|162798|            0.0|\n",
      "|101017|305828|            0.0|\n",
      "| 88344|162798|            0.0|\n",
      "| 88344|134981|            0.0|\n",
      "|162798|170112|            0.0|\n",
      "|113414|311227|            0.0|\n",
      "| 40479|107031|            0.0|\n",
      "|  2626|227267|            0.0|\n",
      "| 49138| 81265|            0.0|\n",
      "|115422|279965|            0.0|\n",
      "| 86856|273017|            0.0|\n",
      "|184938|246671|            0.0|\n",
      "|187276|319748|            0.0|\n",
      "|184938|324016|            0.0|\n",
      "| 49651| 85653|            0.0|\n",
      "| 50132|253377|            0.0|\n",
      "|  7038|325068|            0.0|\n",
      "|  7038|313668|            0.0|\n",
      "| 70108| 96548|            0.0|\n",
      "| 87155|177183|            0.0|\n",
      "| 50132| 93572|            0.0|\n",
      "| 82321|230806|            0.0|\n",
      "| 92534|325068|            0.0|\n",
      "|169845|308490|            0.0|\n",
      "| 50132|177183|            0.0|\n",
      "+------+------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sorted_pairs = similar_pairs.orderBy(col(\"JaccardDistance\"))\n",
    "top_100_pairs = sorted_pairs.limit(100)\n",
    "\n",
    "# Show the top 100 pairs\n",
    "top_100_pairs.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid glitches, I saved the top 100 results manually into a .csv file. Then I read that file back into a spark data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:=================================================>   (187 + 13) / 200]\r"
     ]
    }
   ],
   "source": [
    "# result_path_csv = \"new_top_100_pairs.csv\"\n",
    "\n",
    "# # Write the DataFrame to a CSV file\n",
    "# top_100_pairs.write.csv(result_path_csv, header=True)\n",
    "\n",
    "# # result_path_parquet = \"top_100_pairs.parquet\"\n",
    "\n",
    "# # # Write the DataFrame to a Parquet file\n",
    "# # top_100_pairs.write.parquet(result_path_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "results = spark.read.csv(\"results_50.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---------------+\n",
      "|   idA|   idB|JaccardDistance|\n",
      "+------+------+---------------+\n",
      "| 85653| 95175|            0.0|\n",
      "|305904|314085|            0.0|\n",
      "| 51160| 62784|            0.0|\n",
      "| 57540|282312|            0.0|\n",
      "| 77600|132822|            0.0|\n",
      "| 64872|293880|            0.0|\n",
      "| 82321|236540|            0.0|\n",
      "|158283|329248|            0.0|\n",
      "| 82321|277862|            0.0|\n",
      "| 19061|241234|            0.0|\n",
      "| 97685|134981|            0.0|\n",
      "| 22437| 23527|            0.0|\n",
      "|234310|325068|            0.0|\n",
      "|  3799| 97685|            0.0|\n",
      "| 12125| 47942|            0.0|\n",
      "| 50132| 87155|            0.0|\n",
      "|183207|222150|            0.0|\n",
      "|122621|235844|            0.0|\n",
      "| 77318|227884|            0.0|\n",
      "| 83065|183123|            0.0|\n",
      "+------+------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/15 16:48:55 WARN TaskSetManager: Stage 15 contains a task of very large size (1107 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 15:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|         movieVector|\n",
      "+------+--------------------+\n",
      "|   148|(86537,[0,1,5,6,9...|\n",
      "|   463|(86537,[0,109,220...|\n",
      "|   496|(86537,[5,9,16,20...|\n",
      "|   833|(86537,[46,108,25...|\n",
      "|  1088|(86537,[0,1,5,9,2...|\n",
      "|  1238|(86537,[5,9,15,16...|\n",
      "|  1342|(86537,[31,46,228...|\n",
      "|  1645|(86537,[0,16,27,4...|\n",
      "|  1829|(86537,[4,30,33,4...|\n",
      "|  1959|(86537,[0,1,10,47...|\n",
      "|  2122|(86537,[46,59,578...|\n",
      "|  2142|(86537,[1,5,9,10,...|\n",
      "|  2366|(86537,[9,46,108,...|\n",
      "|  2659|(86537,[102,214,2...|\n",
      "|  3175|(86537,[0,5,8,9,1...|\n",
      "|  3749|(86537,[0,1,2,9,1...|\n",
      "|  3918|(86537,[9,16,27,2...|\n",
      "|  4101|(86537,[0,257,475...|\n",
      "|  4900|(86537,[18,20,46,...|\n",
      "|  4935|(86537,[163,1013,...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "loaded_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(userA, userB):\n",
    "    df = loaded_data \n",
    "    # Fetch movie vectors for the given user IDs\n",
    "    vectorA = df.filter(df.userId == userA).select(\"movieVector\").rdd.map(lambda x: x[0]).collect()[0]\n",
    "    vectorB = df.filter(df.userId == userB).select(\"movieVector\").rdd.map(lambda x: x[0]).collect()[0]\n",
    "    \n",
    "    # Convert arrays to sets\n",
    "    setA = set(vectorA.indices)\n",
    "    setB = set(vectorB.indices)\n",
    "    \n",
    "    # Calculate intersection and union of non-zero elements\n",
    "    intersection = setA.intersection(setB)\n",
    "    union = setA.union(setB)\n",
    "    \n",
    "    # Calculate Jaccard similarity\n",
    "    similarity = len(intersection) / len(union)\n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/15 16:49:09 WARN TaskSetManager: Stage 16 contains a task of very large size (1107 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/05/15 16:49:16 WARN TaskSetManager: Stage 17 contains a task of very large size (1107 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = jaccard_similarity(85653, 95175)\n",
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/15 17:24:01 WARN TaskSetManager: Stage 516 contains a task of very large size (1107 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/05/15 17:24:02 WARN TaskSetManager: Stage 517 contains a task of very large size (1107 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = loaded_data\n",
    "vectorA = df.filter(df.userId == 85653).select(\"movieVector\").rdd.map(lambda x: x[0]).collect()[0]\n",
    "vectorB = df.filter(df.userId == 95175).select(\"movieVector\").rdd.map(lambda x: x[0]).collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(86537, {9: 1.0, 148: 1.0, 151: 1.0, 159: 1.0, 163: 1.0, 183: 1.0, 206: 1.0, 228: 1.0, 250: 1.0, 288: 1.0, 292: 1.0, 312: 1.0, 314: 1.0, 324: 1.0, 334: 1.0, 339: 1.0, 344: 1.0, 375: 1.0, 429: 1.0, 452: 1.0, 580: 1.0, 582: 1.0, 584: 1.0, 585: 1.0, 587: 1.0})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(86537, {9: 1.0, 148: 1.0, 151: 1.0, 159: 1.0, 163: 1.0, 183: 1.0, 206: 1.0, 228: 1.0, 250: 1.0, 288: 1.0, 292: 1.0, 312: 1.0, 314: 1.0, 324: 1.0, 334: 1.0, 339: 1.0, 344: 1.0, 375: 1.0, 429: 1.0, 452: 1.0, 580: 1.0, 582: 1.0, 584: 1.0, 585: 1.0, 587: 1.0})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/15 17:02:31 WARN TaskSetManager: Stage 107 contains a task of very large size (1107 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/05/15 17:02:33 WARN TaskSetManager: Stage 110 contains a task of very large size (1107 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(131695, 4592),\n",
       " (310427, 217769),\n",
       " (209383, 184581),\n",
       " (326980, 82753),\n",
       " (276509, 282499),\n",
       " (322988, 206986),\n",
       " (102018, 170246),\n",
       " (120095, 196785),\n",
       " (64421, 148543),\n",
       " (130900, 314043)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "import random\n",
    "\n",
    "# Get all userIds from loaded_data\n",
    "all_userIds = loaded_data.select(\"userId\").distinct()\n",
    "\n",
    "# Count the number of distinct userIds\n",
    "num_userIds = all_userIds.count()\n",
    "\n",
    "# Randomly select 100 userIds\n",
    "userIds = all_userIds.orderBy(col(\"userId\"))\n",
    "\n",
    "user_ids = [row['userId'] for row in df.collect()]\n",
    "\n",
    "i = 0\n",
    "random_pairs = []\n",
    "while i < 100:\n",
    "    user_id_1 = user_ids[random.randint(0, num_userIds)]\n",
    "    user_id_2 = user_ids[random.randint(0, num_userIds)]\n",
    "    if user_id_1 != user_id_2:\n",
    "        i += 1\n",
    "        random_pairs.append((user_id_1, user_id_2))\n",
    "\n",
    "random_pairs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_pair_results = []\n",
    "for user_id_1, user_id_2 in random_pairs:\n",
    "    similarity = jaccard_similarity(user_id_1, user_id_2)\n",
    "    random_pair_results.append((user_id_1, user_id_2, similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(131695, 4592, 0.023923444976076555),\n",
       " (310427, 217769, 0.005291005291005291),\n",
       " (209383, 184581, 0.11700680272108843),\n",
       " (326980, 82753, 0.022727272727272728),\n",
       " (276509, 282499, 0.038461538461538464),\n",
       " (322988, 206986, 0.0),\n",
       " (102018, 170246, 0.05555555555555555),\n",
       " (120095, 196785, 0.04416403785488959),\n",
       " (64421, 148543, 0.10666666666666667),\n",
       " (130900, 314043, 0.031317754757889664)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_pair_results[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'random_pairs_similarity.csv' has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "filename = \"random_pairs_similarity.csv\"\n",
    "\n",
    "# Write data to CSV file\n",
    "with open(filename, 'w', newline='') as csvfile:\n",
    "    # Define column names\n",
    "    fieldnames = ['user_id_1', 'user_id_2', 'jaccard_similarity']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    # Write the header\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Write each row of data\n",
    "    for row in random_pair_results:\n",
    "        writer.writerow({'user_id_1': row[0], 'user_id_2': row[1], 'jaccard_similarity': row[2]})\n",
    "\n",
    "print(f\"CSV file '{filename}' has been created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(85653, 95175),\n",
       " (305904, 314085),\n",
       " (51160, 62784),\n",
       " (57540, 282312),\n",
       " (77600, 132822),\n",
       " (64872, 293880),\n",
       " (82321, 236540),\n",
       " (158283, 329248),\n",
       " (82321, 277862),\n",
       " (19061, 241234)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's calculate jaccard similarity for the chosen twin pairs\n",
    "twin_pairs = [(row['idA'], row['idB']) for row in results.collect()]\n",
    "\n",
    "# Print the list of tuples\n",
    "twin_pairs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twin_pair_results = []\n",
    "for user_id_1, user_id_2 in twin_pairs:\n",
    "    similarity = jaccard_similarity(user_id_1, user_id_2)\n",
    "    twin_pair_results.append((user_id_1, user_id_2, similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(85653, 95175, 1.0),\n",
       " (305904, 314085, 1.0),\n",
       " (51160, 62784, 1.0),\n",
       " (57540, 282312, 1.0),\n",
       " (77600, 132822, 1.0),\n",
       " (64872, 293880, 1.0),\n",
       " (82321, 236540, 1.0),\n",
       " (158283, 329248, 1.0),\n",
       " (82321, 277862, 1.0),\n",
       " (19061, 241234, 1.0)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twin_pair_results[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'twin_pairs_similarity.csv' has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "filename = \"twin_pairs_similarity.csv\"\n",
    "\n",
    "# Write data to CSV file\n",
    "with open(filename, 'w', newline='') as csvfile:\n",
    "    # Define column names\n",
    "    fieldnames = ['user_id_1', 'user_id_2', 'jaccard_similarity']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    # Write the header\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Write each row of data\n",
    "    for row in twin_pair_results:\n",
    "        writer.writerow({'user_id_1': row[0], 'user_id_2': row[1], 'jaccard_similarity': row[2]})\n",
    "\n",
    "print(f\"CSV file '{filename}' has been created successfully.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
